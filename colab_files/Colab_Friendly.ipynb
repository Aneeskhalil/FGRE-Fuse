{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt4_sXdUGxFA"
      },
      "source": [
        "# infrared and Visible fused images Super-Resolution module Notebook simplified\n",
        "\n",
        "\n",
        "This notebook processes all images in a specified folder sequentially, one image at a time at full resolution, with optimized memory management for Google Colab T4 GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teE_s2olGxFC"
      },
      "source": [
        "## 1. SETUP CELL - Run First"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIUtb1kpGxFD",
        "outputId": "391d90c5-4919-4ff2-d3f5-474b73ef3fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Using device: cuda\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive and import libraries\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "import glob\n",
        "import gc\n",
        "\n",
        "\n",
        "# Set PyTorch CUDA memory management\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0)}\" if torch.cuda.is_available() else \"No GPU available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4ChBufqGxFE"
      },
      "source": [
        "## 2. MODEL DEFINITION CELL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5CIzhCqGGxFE"
      },
      "outputs": [],
      "source": [
        "class ResidualDenseBlock(nn.Module):\n",
        "    def __init__(self, channels, growth_channels=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, growth_channels, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(channels + growth_channels, growth_channels, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(channels + 2*growth_channels, growth_channels, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(channels + 3*growth_channels, channels, 3, padding=1)\n",
        "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.lrelu(self.conv1(x))\n",
        "        x2 = self.lrelu(self.conv2(torch.cat([x, x1], 1)))\n",
        "        x3 = self.lrelu(self.conv3(torch.cat([x, x1, x2], 1)))\n",
        "        x4 = self.conv4(torch.cat([x, x1, x2, x3], 1))\n",
        "        return x + x4 * 0.2\n",
        "\n",
        "class ReversedUBlock(nn.Module):\n",
        "    def __init__(self, channels, scale_factor=2):\n",
        "        super().__init__()\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels * (scale_factor**2), 3, padding=1),\n",
        "            nn.PixelShuffle(scale_factor),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.process = nn.Sequential(\n",
        "            ResidualDenseBlock(channels),\n",
        "            ResidualDenseBlock(channels)\n",
        "        )\n",
        "        self.down = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 3, stride=scale_factor, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(channels, channels, 3, padding=1)\n",
        "        )\n",
        "        self.skip = nn.Conv2d(channels, channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_up = self.up(x)\n",
        "        x_proc = self.process(x_up)\n",
        "        x_down = self.down(x_proc)\n",
        "        return x_down + self.skip(x)\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c = x.shape[:2]\n",
        "        y = self.gap(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * (1 + y)\n",
        "\n",
        "class EnhancedSRUnet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, scale=4, num_rub=3):\n",
        "        super().__init__()\n",
        "        self.scale = scale\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, 3, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.rub_blocks = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                ReversedUBlock(64),\n",
        "                ChannelAttention(64),\n",
        "                ResidualDenseBlock(64)\n",
        "            ) for _ in range(num_rub)\n",
        "        ])\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Conv2d(64*(num_rub+1), 64, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            ChannelAttention(64)\n",
        "        )\n",
        "        self.upsample = nn.Sequential(\n",
        "            nn.Conv2d(64, 64 * (scale**2), 3, padding=1),\n",
        "            nn.PixelShuffle(scale),\n",
        "            nn.Conv2d(64, out_channels, 3, padding=1)\n",
        "        )\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, 32, 3, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(32, out_channels, 3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(next(self.parameters()).device)\n",
        "        x0 = self.head(x)\n",
        "        features = [x0]\n",
        "        for rub in self.rub_blocks:\n",
        "            features.append(rub(features[-1]))\n",
        "        x_fused = self.fusion(torch.cat(features, dim=1))\n",
        "        out = self.upsample(x_fused)\n",
        "        out = out + F.interpolate(x, scale_factor=self.scale, mode='bicubic')\n",
        "        return self.refine(out).clamp_(0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbBAu1prGxFE"
      },
      "source": [
        "## 3. PATH SETUP AND MODEL LOAD CELL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cSacIUoGxFF",
        "outputId": "f6da2d9d-22f5-468e-a93d-5c03104af2de"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "model_path = '//'\n",
        "input_folder = '//'\n",
        "output_folder = '//'\n",
        "excel_path = '//'\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "os.makedirs(input_folder, exist_ok=True)\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Get list of all image files in the input folder\n",
        "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
        "image_paths = []\n",
        "for ext in image_extensions:\n",
        "    image_paths.extend(glob.glob(os.path.join(input_folder, ext)))\n",
        "print(f\"Found {len(image_paths)} images to process\")\n",
        "\n",
        "# Load model once\n",
        "model = EnhancedSRUnet().to(device)\n",
        "try:\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    print(\"Model loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {str(e)}\")\n",
        "    print(f\"Expected model at: {model_path}\")\n",
        "    model = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiP2j0sqGxFF"
      },
      "source": [
        "## 4. IMAGE PROCESSING FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fATA_2QlGxFF"
      },
      "outputs": [],
      "source": [
        "def process_all_images():\n",
        "    if model is None:\n",
        "        print(\"Model not loaded. Cannot process images.\")\n",
        "        return None\n",
        "\n",
        "    model.eval()\n",
        "    processed_images = []\n",
        "\n",
        "    # Process each image sequentially\n",
        "    for img_path in image_paths:\n",
        "        print(f\"\\n=== Processing image: {os.path.basename(img_path)} ===\")\n",
        "\n",
        "        # Clear GPU memory before processing\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        # Load image\n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            print(f\"Original image size: {img.size}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {os.path.basename(img_path)}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Convert to tensor\n",
        "        img_tensor = torch.from_numpy(np.array(img)/255.).permute(2,0,1).unsqueeze(0).float().to(device)\n",
        "\n",
        "        # Memory check\n",
        "        required_memory = img_tensor.nelement() * img_tensor.element_size() * 20  # Rough estimate\n",
        "        total_memory = torch.cuda.get_device_properties(0).total_memory if torch.cuda.is_available() else 0\n",
        "        if torch.cuda.is_available() and required_memory > total_memory:\n",
        "            print(f\"Warning: Image {os.path.basename(img_path)} too large for GPU memory (needs ~{required_memory/1024**3:.1f}GB, available ~{total_memory/1024**3:.1f}GB)\")\n",
        "            del img_tensor\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            continue\n",
        "\n",
        "        # Process entire image\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "                output = model(img_tensor)\n",
        "                print(f\"Processing completed for {os.path.basename(img_path)}\")\n",
        "            except RuntimeError as e:\n",
        "                print(f\"GPU Memory Error for {os.path.basename(img_path)}: {str(e)}\")\n",
        "                print(\"Image size too large for T4 GPU. Consider using a higher-capacity GPU or reducing image size.\")\n",
        "                del img_tensor\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "                continue\n",
        "\n",
        "        # Convert and save output\n",
        "        output_np = output.squeeze().permute(1,2,0).clamp(0,1).cpu().numpy()\n",
        "        output_img = Image.fromarray((output_np*255).astype('uint8'))\n",
        "\n",
        "        # Generate output path\n",
        "        output_filename = os.path.splitext(os.path.basename(img_path))[0] + '_sr.png'\n",
        "        output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "        # Save with maximum quality\n",
        "        output_img.save(output_path, quality=100, subsampling=0)\n",
        "        print(f\"Super-resolved image saved to: {output_path}\")\n",
        "\n",
        "        processed_images.append((output_img, img_path, output_path))\n",
        "\n",
        "        # Clear GPU memory after processing\n",
        "        del img_tensor, output\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    return processed_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B1z2tvspehwt"
      },
      "outputs": [],
      "source": [
        "# 6. BATCH IMAGE PROCESSING FUNCTION  (for Limitd GPU Memory)\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "def post_process_image(image):\n",
        "    img_np = np.array(image).astype(np.float32)\n",
        "    blurred = gaussian_filter(img_np, sigma=1)\n",
        "    sharpened = img_np + (img_np - blurred) * 1.5\n",
        "    sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)\n",
        "    return Image.fromarray(sharpened)\n",
        "\n",
        "def process_all_images():\n",
        "    # Load model with self-ensemble\n",
        "    model = EnhancedSRUnet().to(device)\n",
        "    model = SelfEnsembleWrapper(model)\n",
        "    try:\n",
        "        state_dict = torch.load(model_path, map_location=device)\n",
        "        model.model.load_state_dict(state_dict)\n",
        "        print(\"Model loaded successfully with self-ensemble\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {str(e)}\")\n",
        "        print(f\"Expected model at: {model_path}\")\n",
        "        return None\n",
        "\n",
        "    # Get list of images\n",
        "    image_extensions = ['*.jpg', '*.jpeg', '*.png']\n",
        "    image_paths = []\n",
        "    for ext in image_extensions:\n",
        "        image_paths.extend(glob.glob(os.path.join(input_folder, ext)))\n",
        "\n",
        "    if not image_paths:\n",
        "        print(f\"No images found in {input_folder}\")\n",
        "        return None\n",
        "\n",
        "    # Initialize results list\n",
        "    results = []\n",
        "\n",
        "    model.eval()\n",
        "    for img_path in image_paths:\n",
        "        print(f\"\\nProcessing: {os.path.basename(img_path)}\")\n",
        "\n",
        "        # Load image\n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            print(f\"Original image size: {img.size}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Process image with chunking\n",
        "        output_img = process_image_in_chunks(model, img, device, chunk_size=512, overlap=64)\n",
        "        if output_img is None:\n",
        "            print(f\"Failed to process {img_path}\")\n",
        "            continue\n",
        "\n",
        "        # Apply post-processing\n",
        "        output_img = post_process_image(output_img)\n",
        "\n",
        "        # Save output\n",
        "        output_filename = f\"sr_{os.path.basename(img_path)}\"\n",
        "        output_img_path = os.path.join(output_folder, output_filename)\n",
        "        output_img.save(output_img_path, quality=100, subsampling=0)\n",
        "        print(f\"Super-resolved image saved to: {output_img_path}\")\n",
        "\n",
        "        # Calculate metrics\n",
        "        bicubic_img = img.resize((img.size[0]*4, img.size[1]*4), Image.BICUBIC)\n",
        "        metrics = calculate_metrics(bicubic_img, output_img)\n",
        "        metrics['Image'] = os.path.basename(img_path)\n",
        "        results.append(metrics)\n",
        "\n",
        "        # Clear memory\n",
        "        del output_img, bicubic_img\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # Save results to Excel\n",
        "    if results:\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_excel(excel_path, index=False)\n",
        "        print(f\"\\nMetrics saved to: {excel_path}\")\n",
        "    else:\n",
        "        print(\"\\nNo images were processed successfully.\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn2r2QPB1ONO",
        "outputId": "129a9379-cd49-4927-bf48-d21c5a6bce3e"
      },
      "outputs": [],
      "source": [
        "!pip install -U scikit-image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXbHbAl9GxFF"
      },
      "source": [
        "## 5. EXECUTION CELL - Run Last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O_6OJr2-GxFG",
        "outputId": "f4700ee2-3303-496c-b52c-17ec04852948"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== Starting Image Processing ===\")\n",
        "results = process_all_images()\n",
        "if results:\n",
        "    print(\"\\n=== Processing Summary ===\")\n",
        "    for output_img, input_path, output_path in results:\n",
        "        print(f\"\\nImage: {os.path.basename(input_path)}\")\n",
        "        print(f\"Input dimensions: {Image.open(input_path).size}\")\n",
        "        print(f\"Output dimensions: {output_img.size}\")\n",
        "        display(output_img)\n",
        "else:\n",
        "    print(\"\\nProcessing failed or no images found. Check error messages above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUjq8SAdGxFG"
      },
      "source": [
        "## 6. VERIFICATION CELL (Run if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu6lCDjrGxFG"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== File Verification ===\")\n",
        "print(\"Model exists:\", os.path.exists(model_path))\n",
        "print(\"Input directory exists:\", os.path.exists(input_folder))\n",
        "print(\"Output directory exists:\", os.path.exists(output_folder))\n",
        "print(\"Number of input images found:\", len(image_paths))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
